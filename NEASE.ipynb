{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the network\n",
    "def load_obj(data_folder):\n",
    "    with open(data_folder + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/anaconda3/envs/z1/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "database_mapping={}\n",
    "\n",
    "database_mapping['Human']= pd.read_csv(\"data/database/Human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pathways={}\n",
    "Pathways['Human']= pd.read_pickle(\"data/pathways/pathways_human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network={}\n",
    "network['Human']=load_obj('data/network/graph_human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/anaconda3/envs/z1/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "import  NEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NEASE' from '/home/zakaria/projects/NEASE/NEASE.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platelet dataset \n",
    "table= pd.read_table(\"/home/zakaria/projects/exon_enrch/data/platelets_ds/MAJIQ/healthy-mp_healthy-rp_deltapsi/RP_MP.deltapsi.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the standard input for DCM data\n",
    "table_dcm=pd.read_csv('/home/zakaria/projects/NEASE/RNA-Seq datasets/dcm.csv')\n",
    "mapping_tmp=database_mapping['Human'][['Gene stable ID','Gene name']].drop_duplicates()\n",
    "\n",
    "table_dcm=pd.merge(table_dcm, mapping_tmp,  left_on='gene_id', right_on='Gene name')\n",
    "\n",
    "\n",
    "table_dcm=table_dcm[['Gene stable ID','new_start','new_end', 'beta' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to convert IDs \n",
    "\n",
    "def Entrez_to_name(gene,mapping):\n",
    "    try:\n",
    "        \n",
    "        return mapping[mapping['NCBI gene ID']==int(gene)]['Gene name'].unique()[0]\n",
    "    \n",
    "    except KeyError:\n",
    "        return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene stable ID</th>\n",
       "      <th>new_start</th>\n",
       "      <th>new_end</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000154263</td>\n",
       "      <td>69314431</td>\n",
       "      <td>69315425</td>\n",
       "      <td>-0.105828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000154265</td>\n",
       "      <td>69314431</td>\n",
       "      <td>69315425</td>\n",
       "      <td>-0.105828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000005471</td>\n",
       "      <td>87411893</td>\n",
       "      <td>87412033</td>\n",
       "      <td>0.135682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000197150</td>\n",
       "      <td>151031241</td>\n",
       "      <td>151031291</td>\n",
       "      <td>0.150763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000124574</td>\n",
       "      <td>43431751</td>\n",
       "      <td>43432141</td>\n",
       "      <td>0.107582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>ENSG00000162086</td>\n",
       "      <td>3313049</td>\n",
       "      <td>3313175</td>\n",
       "      <td>0.131544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>ENSG00000198482</td>\n",
       "      <td>52547512</td>\n",
       "      <td>52547638</td>\n",
       "      <td>-0.104090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>ENSG00000176371</td>\n",
       "      <td>84616309</td>\n",
       "      <td>84616614</td>\n",
       "      <td>-0.246228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>ENSG00000140987</td>\n",
       "      <td>3397745</td>\n",
       "      <td>3397787</td>\n",
       "      <td>-0.161007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>ENSG00000070476</td>\n",
       "      <td>126461083</td>\n",
       "      <td>126461534</td>\n",
       "      <td>0.219728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1027 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene stable ID  new_start    new_end      beta\n",
       "0     ENSG00000154263   69314431   69315425 -0.105828\n",
       "1     ENSG00000154265   69314431   69315425 -0.105828\n",
       "2     ENSG00000005471   87411893   87412033  0.135682\n",
       "3     ENSG00000197150  151031241  151031291  0.150763\n",
       "4     ENSG00000124574   43431751   43432141  0.107582\n",
       "...               ...        ...        ...       ...\n",
       "1022  ENSG00000162086    3313049    3313175  0.131544\n",
       "1023  ENSG00000198482   52547512   52547638 -0.104090\n",
       "1024  ENSG00000176371   84616309   84616614 -0.246228\n",
       "1025  ENSG00000140987    3397745    3397787 -0.161007\n",
       "1026  ENSG00000070476  126461083  126461534  0.219728\n",
       "\n",
       "[1027 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to process AS tools outputs\n",
    "import re\n",
    "import collections\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DIGGER Exon-level link: \n",
    "\"\"\"Domain Interaction Graph Guided ExploreR (DIGGER) integrates protein-protein interactions and domain-domain interactions\n",
    "into a joint graph and maps interacting residues to exons. DIGGER allows the users to query exons or isoforms individually or as a set \n",
    "to visually explore their interactions. The following modes of DIGGER can be used interchangeably:\n",
    "\"\"\"\n",
    "DIGGER='https://exbio.wzw.tum.de/digger/ID/exon/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def splitDataFrameList(df,target_column):\n",
    "\n",
    "        ''' \n",
    "        Efficiently split Pandas Dataframe cells containing lists into multiple rows,\n",
    "        duplicating the other column's values.\n",
    "        Original code from https://gist.github.com/jlln/338b4b0b55bd6984f883\n",
    "\n",
    "        df = dataframe to split,\n",
    "        target_column = the column containing the values to split\n",
    "        separator = the symbol used to perform the split\n",
    "        returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "        The values in the other columns are duplicated across the newly divided rows.\n",
    "        '''\n",
    "\n",
    "        def splitListToRows(row,row_accumulator,target_column):\n",
    "            split_row = row[target_column]\n",
    "            for s in split_row:\n",
    "                new_row = row.to_dict()\n",
    "                new_row[target_column] = s\n",
    "                row_accumulator.append(new_row)\n",
    "        new_rows = []\n",
    "        df.apply(splitListToRows,axis=1,args = (new_rows,target_column))\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        return new_df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Standard data processing \n",
    "# Gene ID     Start       End        Delta  (optionally) \n",
    "\n",
    "\n",
    "def process_standard (data,\n",
    "                      mapping,\n",
    "                      min_delta):\n",
    "    \n",
    "        # verify the input data format\n",
    "        columns=data.columns\n",
    "\n",
    "        # make sure you have at least two columns\n",
    "        if len(columns)<3:\n",
    "                raise ValueError('Make sure your table have at least 3 columns:    Gene ensembl ID    EXON START    EXON END    dPSI (optional)')\n",
    "\n",
    "        else:\n",
    "                genes=list(data[columns[0]])\n",
    "\n",
    "                # Verify the gene IDs\n",
    "                if not  all(x.startswith('ENS') for x in genes):\n",
    "                     raise ValueError(' Could not recognize Ensembl gene ID. Please make sure that the first column corresponds to gene IDs.')\n",
    "\n",
    "                # Verify the start and end\n",
    "                try:\n",
    "                    data[columns[1]]=data[columns[1]].astype(int)\n",
    "                    data[columns[2]]=data[columns[2]].astype(int)\n",
    "                except:\n",
    "                    raise ValueError('Could not find exons coordinates. Please make sure that the second column corresponds to the exon start and the third to the exon end (hg38).')\n",
    "\n",
    "\n",
    "\n",
    "        # map to domains by calculating the overlap of exon coordinate and domain\n",
    "        mapping_tb=pd.merge(data, mapping,   left_on=columns[0], right_on='Gene stable ID').drop_duplicates()        \n",
    "        \n",
    "        # any overlap is considered\n",
    "        mapping_tb['overl']=mapping_tb[[\"Genomic coding start\", \"new_start\"]].max(axis=1) <= mapping_tb[[\"Genomic coding end\", \"new_end\"]].min(axis=1)\n",
    "        mapping_tb=mapping_tb[mapping_tb['overl']].drop_duplicates()\n",
    "        \n",
    "        try:\n",
    "                #try to get the delta PSI from the user input\n",
    "                mapping_tb['max_change']=mapping_tb[columns[3]]\n",
    "                \n",
    "                # significance filter (delta PSI)\n",
    "                mapping_tb=mapping_tb[mapping_tb['max_change'].abs()>=min_delta]\n",
    "        except:\n",
    "                # No delta PSI given\n",
    "                mapping_tb['max_change']='-'\n",
    "                \n",
    "                \n",
    "                \n",
    "        mapping_tb=mapping_tb[['Gene name','NCBI gene ID','Gene stable ID','Exon stable ID','Pfam ID','max_change']]\n",
    "        #mapping_tb=mapping_tb.sort_values(['max_change'].abs(), ascending=False)\n",
    "        \n",
    "        mapping_tb=mapping_tb.reindex(mapping_tb['max_change'].abs().sort_values(ascending=False).index)\n",
    "        \n",
    "        mapping_tb=mapping_tb[mapping_tb['NCBI gene ID'].notnull()]\n",
    "        mapping_tb['NCBI gene ID']=mapping_tb['NCBI gene ID'].astype('int').astype('str')\n",
    "        #mapping_tb=mapping_tb.drop_duplicates(['Gene name','NCBI gene ID','Gene stable ID','Pfam ID'],keep= 'first')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #mapping_tb=mapping_tb.groupby(['Gene name','NCBI gene ID','Gene stable ID','Exon stable ID','Pfam ID']).max()['max_change']\n",
    "\n",
    "        \n",
    "        return mapping_tb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Majiq output\n",
    "def process_MAJIQ(data,\n",
    "                  mapping,\n",
    "                  Majiq_confidence=0.95, \n",
    "                  min_delta=0.05 ):\n",
    "    \n",
    "        # extract exon skipping events:\n",
    "        data=data[ data['ES']==True]\n",
    "        \n",
    "        \n",
    "        # helper functions:\n",
    "        print('Processing MAJIQ format...')\n",
    "        f = lambda x: [abs(float(y)) for y in x.split(';')]\n",
    "        l=lambda x:  any( y >= min_delta for y in x )\n",
    "        data=data\n",
    "        # get Delta PSI values for each junction\n",
    "        data[\"delta\"] = data['E(dPSI) per LSV junction'].apply(f)\n",
    "        data[\"P(|dPSI|>=0.20)\"] = data['P(|dPSI|>=0.20) per LSV junction'].apply(f)\n",
    "\n",
    "        data[\"delta_sif\"] = data['delta'].apply(l)\n",
    "        data=data[ data['delta_sif']]\n",
    "\n",
    "        #filter for significant of diff. AS events\n",
    "        # only keep diff used junction with confidence higher than 'Majiq_confidence' (for instance: 0.95)\n",
    "\n",
    "        l=lambda x:  any( y >=Majiq_confidence for y in x )\n",
    "        data[\"delta_sif\"] = data['P(|dPSI|>=0.20)'].apply(l)\n",
    "        data=data[ data['delta_sif']]\n",
    "\n",
    "        z= lambda x: x.split(':')[1]\n",
    "        data['Gene ID'] = data['Gene ID'].apply(z)\n",
    "    \n",
    "    \n",
    "        junctions=list(data['Junctions coords'])\n",
    "        confidence=list(data['P(|dPSI|>=0.20)'])   \n",
    "        junc_confid=dict(zip(junctions, confidence))\n",
    "        \n",
    "        \n",
    "        complexx=0\n",
    "        jun_to_target={}\n",
    "        jun_to_source={}\n",
    "        for j in junc_confid.keys():\n",
    "            #find the source of the junction\n",
    "            x=re.findall(r\"[\\w']+\", j)\n",
    "            #print(x)\n",
    "            source=list(set([l for l in x if x.count(l) == len(x)/2]))\n",
    "\n",
    "            #complex events : skip for now\n",
    "            # TO DO later\n",
    "            if len(source)==0:      complexx+=1\n",
    "\n",
    "            #source found\n",
    "            #search for all possible targets\n",
    "            else: \n",
    "                targets=[ y for y in x if y not in source ]\n",
    "\n",
    "\n",
    "                #check if we have correct confidence for every target\n",
    "                if len(targets)==len(junc_confid[j]):\n",
    "\n",
    "                    #filter low confident diff used event\n",
    "                    targets=[ x  for x,y in zip(targets, junc_confid[j]) if y>= 0.95]\n",
    "\n",
    "                    #save\n",
    "                    jun_to_target[j]=targets\n",
    "                    jun_to_source[j]=int(source[0])\n",
    "        \n",
    "        \n",
    "        t=lambda x:  jun_to_target[x] if x in jun_to_target.keys() else False\n",
    "        data[\"targets\"] = data['Junctions coords'].apply(t)\n",
    "        \n",
    "        \n",
    "        g=lambda x:  jun_to_source[x] if x in jun_to_source.keys() else False\n",
    "        data[\"source\"] = data['Junctions coords'].apply(g)\n",
    "        \n",
    "        \n",
    "        data=data[data['targets']!=False]\n",
    "        \n",
    "        data=splitDataFrameList(data,'targets')\n",
    "        \n",
    "        \n",
    "        mapping_tb=[]\n",
    "        \n",
    "        # check mapped exons\n",
    "        if len(data)==0:\n",
    "                    print('None of MAJIQ junctions maps to annotated exons (Ensembl Exons). Try to use the standard input instead.')\n",
    "\n",
    "        else:\n",
    "                data=data  [ [ 'Gene ID','E(dPSI) per LSV junction' , 'Junctions coords','P(|dPSI|>=0.20) per LSV junction','delta','targets','source' ]]\n",
    "\n",
    "                data['targets']=data['targets'].astype(int)\n",
    "\n",
    "\n",
    "                #Map exons to domain\n",
    "                mapping_tb=pd.merge(mapping, data,  left_on='Genomic coding start', right_on='targets')\n",
    "\n",
    "                #check if the mapping based on coordinate match the gene ID provided from Majiq\n",
    "                mapping_tb=mapping_tb[mapping_tb['Gene ID']==mapping_tb['Gene stable ID']]\n",
    "\n",
    "                m= lambda x: max(list(x))\n",
    "                mapping_tb['max_change']=mapping_tb['delta'].apply(m)\n",
    "\n",
    "                mapping_tb=mapping_tb[['Exon stable ID','Gene name',\n",
    "                               'NCBI gene ID','Gene stable ID','Genomic coding start','Genomic coding end','max_change','Pfam ID','source','targets']]\n",
    "\n",
    "\n",
    "                mapping_tb=mapping_tb.sort_values(['max_change'], ascending=False)\n",
    "                mapping_tb=mapping_tb[mapping_tb['NCBI gene ID'].notnull()]\n",
    "                mapping_tb['NCBI gene ID']=mapping_tb['NCBI gene ID'].astype('int').astype('str')\n",
    "                mapping_tb=mapping_tb.drop_duplicates()\n",
    "\n",
    "                # an extra filtering step\n",
    "                # make sure that the source belong to an annotated exon \n",
    "                #mapping_tb=pd.merge(mapping[['Genomic coding end']], mapping_tb,  left_on='Genomic coding end', right_on='source')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                mapping_tb=mapping_tb[['Gene name','NCBI gene ID','Gene stable ID','Exon stable ID','Pfam ID','max_change']].drop_duplicates()\n",
    "\n",
    "\n",
    "                print('MAJIQ output converted successfully to NEASE format.')\n",
    "\n",
    "\n",
    "        return mapping_tb\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proccess functions\n",
    "\n",
    "        \n",
    "        \n",
    "def exons_to_edges(mapped,G):\n",
    "        # check if domains have known interactions/binding:\n",
    "        mapped['domain']=mapped['NCBI gene ID']+'/'+mapped['Pfam ID']\n",
    "        mapped['Interacting domain']=mapped['domain'].apply(lambda x: G.has_node(x))\n",
    "        mapped=mapped.rename(columns={\"max_change\": \"dPSI\",\n",
    "                                      \"domain\": \"Domain ID\"}).reset_index(drop=True) \n",
    "    \n",
    "        mapped['Visualization link']=''\n",
    "        mapped.loc[mapped['Interacting domain'],['Visualization link']]=DIGGER+mapped['Exon stable ID']\n",
    "        return mapped\n",
    "    \n",
    "    \n",
    "\n",
    "def affected_edges(data,Join,mapping):\n",
    "\n",
    "            # get domains with DDIs\n",
    "            interacting_domains=data[data['Interacting domain']]\n",
    "\n",
    "\n",
    "\n",
    "            # Identify binding of affected domains = Edges in the PPI\n",
    "\n",
    "            t=lambda node: [  x for x in list(set([x.split('/')[0] for x in \n",
    "                                            [n for n in Join.neighbors(node)] ])) ]\n",
    "            interacting_domains['Affected binding (NCBI)']=interacting_domains['Domain ID'].apply(t)\n",
    "\n",
    "            #Convert IDs to names\n",
    "            c=lambda x: [ Entrez_to_name(gene,mapping) for gene in list(set(x))]\n",
    "            interacting_domains['Affected binding']=interacting_domains['Affected binding (NCBI)'].apply(c)\n",
    "\n",
    "            # count number of affected PPI for every domain\n",
    "            count=lambda x: len(x)\n",
    "            interacting_domains['Number of affected interactions']=interacting_domains['Affected binding'].apply(count)\n",
    "\n",
    "    \n",
    "            return interacting_domains\n",
    "    \n",
    "    \n",
    "def gene_to_edges(data):\n",
    "    \n",
    "    #For every gene get all edges\n",
    "        gene_edges={}\n",
    "        for gene in data['NCBI gene ID'].unique():\n",
    "            edges=data[data['NCBI gene ID']==gene]['Affected binding (NCBI)']\n",
    "            edges=[item for sublist in edges for item in sublist]\n",
    "            \n",
    "            gene_edges[gene]=list(set(edges))\n",
    "        return gene_edges\n",
    "    \n",
    "    \n",
    "def pathway_enrichment(g2edges,paths, mapping,organism):\n",
    "    # General enrichment analysis\n",
    "    \n",
    "    pathway_genes=[]\n",
    "    # Totat degree of structural network for human (pre-computer)\n",
    "    # For statistical test: edge enrichment\n",
    "    # TO DO for mouse\n",
    "    if organism=='Human':\n",
    "        n=52467\n",
    "    \n",
    "    # number of effected edges \n",
    "    affected_edges=len([item for sublist in g2edges.values() for item in sublist])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # for every path :\n",
    "    path_name=[]\n",
    "    path_id=[]\n",
    "    source=[]\n",
    "    genes=[]\n",
    "    p_values=[]\n",
    "    score=[]\n",
    "    \n",
    "    for path in list(paths['pathway']):\n",
    "        # count of affected edges connected to the pathway\n",
    "        # specific to that pathway list p\n",
    "        # initialise the variable for every path \n",
    "        connected=0\n",
    "        genes_tmp=[]\n",
    "        gene_count=0\n",
    "        \n",
    "        try:\n",
    "            # get path total degree \"p\" and gene list\n",
    "            p=int(paths [paths['pathway']==path]['Degree in the structural PPI'])\n",
    "            path_genes=list(paths [paths['pathway']==path]['entrez_gene_ids'])[0]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for gene in g2edges:\n",
    "                # for every affected gene\n",
    "                # count affected gene edges connected to the \n",
    "                # specific to the gene and to the pathway list\n",
    "                tmp=len([x for x in g2edges[gene] if x in path_genes ])\n",
    "\n",
    "                if tmp>0:\n",
    "                    # gene with edges connected to the pathway\n",
    "                    \n",
    "                    gene_count=gene_count+1\n",
    "                    # increment for path edges\n",
    "                    connected=connected+tmp\n",
    "                    \n",
    "                    # add gene to the gene list of the pathway\n",
    "                    genes_tmp.append(Entrez_to_name(gene,mapping) +\" (\"+str(tmp)+\")\")\n",
    "        \n",
    "        \n",
    "        #  affected edges not connected to tha pathway\n",
    "        not_connected=affected_edges-connected\n",
    "        \n",
    "        # Join function is slow can be optimized later \n",
    "        if genes_tmp==[]: genes_tmp= ''\n",
    "        else: genes_tmp=(\", \").join(genes_tmp)\n",
    "            \n",
    "        # Run hypergeometric test on affected edges\n",
    "        _,p_value_tmp=edge_enrich(connected ,not_connected , p, n)\n",
    "        \n",
    "    \n",
    "\n",
    "        p_values.append(p_value_tmp)\n",
    "        \n",
    "        #compute combined score\n",
    "        #score.append( (1+(gene_count/2)) * -np.log(p_value_tmp) )\n",
    "        path_name.append(path)\n",
    "        source.append(list(paths[paths['pathway']==path]['source'])[0])   \n",
    "        path_id.append(list(paths[paths['pathway']==path]['external_id'])[0]) \n",
    "        genes.append(genes_tmp)\n",
    "\n",
    "        \n",
    "    # save results\n",
    "    Enrichment = pd.DataFrame(list(zip(path_id, path_name,source, genes,p_values)), \n",
    "                              columns= ['Pathway ID', 'Pathway name', 'Source', 'Spliced genes (number of interactions affecting the pathway)', \"p_value\"] )\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return Enrichment.sort_values(['p_value'], ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "def single_path_enrich(path_id,Pathways,g2edges,mapping,organism):\n",
    "        \n",
    "\n",
    "        \n",
    "        # Totat degree of structural network for human (pre-computer)\n",
    "        # For statistical test: edge enrichment\n",
    "        # TO DO for mouse\n",
    "        if organism=='Human':\n",
    "            n=52467\n",
    "            \n",
    "        p=int(Pathways [Pathways['external_id']==path_id]['Degree in the structural PPI'])\n",
    "        path_genes=list(Pathways [Pathways['external_id']==path_id]['entrez_gene_ids'])[0]\n",
    "        \n",
    "        #collect:\n",
    "        spliced_genes=[]\n",
    "        gene_association=[]\n",
    "        num=[]\n",
    "        affected_edges=[]\n",
    "        affected_edges_entrez=[]\n",
    "        p_val=[]\n",
    "        \n",
    "        for g in g2edges:\n",
    "            \n",
    "            # affected edges of the gene g\n",
    "            affected=g2edges[g]\n",
    "            \n",
    "            # edges connected to the pathway\n",
    "            edges=[x for x in affected if x in path_genes ]\n",
    "            a=len(edges)\n",
    "            \n",
    "            # Not connected\n",
    "            b=len(affected)-a\n",
    "\n",
    "            if a!=0:\n",
    "                # calculate gene specific p_value:\n",
    "                _,p_value=edge_enrich(a,b,p,n)\n",
    "                \n",
    "                # Save results\n",
    "                spliced_genes.append(Entrez_to_name(g,mapping))\n",
    "                gene_association.append(g in path_genes)\n",
    "                num.append(str(a)+'/'+str(a+b))\n",
    "                affected_edges.append((',').join([ Entrez_to_name(x,mapping) for x in edges]))\n",
    "                affected_edges_entrez.append((',').join(edges))\n",
    "                p_val.append(p_value)\n",
    "\n",
    "                \n",
    "                \n",
    "        Enrichment = pd.DataFrame(list(zip(spliced_genes,gene_association, num,p_val, affected_edges,affected_edges_entrez)), \n",
    "                          columns= ['Spliced genes', 'Gene knwon to be in the pathway','Percentage of edges associated to the pathway', 'p_value', 'Affected binding (edges)','Affected binding (NCBI)'] )\n",
    "        return Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test\n",
    "# Edge enrichment test\n",
    "\n",
    "def edge_enrich(a,b,p,n):\n",
    "    #function to calculate P value\n",
    "    #test if affected edges by AS are significally enriched in a pathway\n",
    "    # fisher exact test\n",
    "    # a+b affected adges, with a the one linked to pathway p\n",
    "    #p total degree of pathway p\n",
    "    #n total edges in the ppi used.\n",
    "    \n",
    "    #linked to pathway but not affected\n",
    "    c=p-a\n",
    "    \n",
    "    # background of test: not linked to p and not affected edges\n",
    "    d=(2*n)-p-b\n",
    "    \n",
    "    # retun oddsratio and pvalue from fisher exact test\n",
    "    return   stats.fisher_exact([[a, b], [c, d]], alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEASE (object):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 data ,\n",
    "                 organism,\n",
    "                 input_type='Standard',\n",
    "                 min_delta=0.05,\n",
    "                 Majiq_confidence=0.95):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "            data: dataframe with list of (diff.) splicing events or junctions. \n",
    "                \n",
    "                Standard input: Ensemble gene ID    Start of exon  End of exon\n",
    "                for external tools, Please change the  input_type to \"MAJIQ\",...\n",
    "                #TO DO\n",
    "         \"\"\"\n",
    "        self.data=[]\n",
    "        self.organism=organism\n",
    "        \n",
    "        if organism!='Human' and organism!='Mouse':\n",
    "            print('Error: Please choose one of the  supported  organism: \"Human\" and \"Mouse\".')\n",
    "        \n",
    "     \n",
    "\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            # TO DO\n",
    "            \n",
    "            #Open the Join graph and databases of the selected organism:\n",
    "            Join=network[organism]\n",
    "            self.mapping=database_mapping[organism]\n",
    "            self.path=Pathways[organism]\n",
    "            \n",
    "            self.data=[]\n",
    "            if input_type=='MAJIQ':\n",
    "\n",
    "                # Processing Majiq output\n",
    "                #try:\n",
    "                    self.data=process_MAJIQ(data,self.mapping, Majiq_confidence, min_delta )\n",
    "                    if len(self.data)==0:\n",
    "                        print('Found no overlap with protein domains.')\n",
    "                #except:\n",
    "                #       print('Could not recognize MAJIQ format. Please make sure your table matches MAJIQ output or use the standard format.')\n",
    "            \n",
    "            \n",
    "            \n",
    "            elif input_type=='Standard':\n",
    "                    \n",
    "                #try:\n",
    "                    self.data=process_standard(data,self.mapping,min_delta )\n",
    "                    if len(self.data)==0:\n",
    "                        print('Found no overlap with protein domains.')\n",
    "                        print('Make sure that the genomic coordinates of the exons correspond to the human genome build hg38 (GRCh38).')\n",
    "\n",
    "                    \n",
    "                #except:\n",
    "                #                print('Could not recognize the standard format. Please make sure your table matches the standard format.')\n",
    "                #                print('Gene ensembl ID          EXON START        EXON END          dPSI (optional)')\n",
    "                #                print('Make sure that the genomic coordinates of the exons correspond to the human genome build hg38 (GRCh38).')\n",
    "                    \n",
    "            \n",
    "            else:\n",
    "                self.data=data\n",
    "        \n",
    "\n",
    "\n",
    "            self.data=self.data.drop_duplicates(['Gene name','NCBI gene ID','Gene stable ID','Pfam ID'],keep= 'first')\n",
    "\n",
    "\n",
    "            if len(self.data)==0:\n",
    "                print('process canceled...')\n",
    "\n",
    "\n",
    "            else : \n",
    "                # check interaction of the domains\n",
    "                self.data=exons_to_edges(self.data,Join)\n",
    "                print('\\n\\t\\tData Summary')\n",
    "                print('**************************************************')\n",
    "\n",
    "                print(str(len(self.data['Pfam ID'].unique()))+' protein domains are affected by AS.\\n'\n",
    "                      + str(len(self.data[self.data['Interacting domain']]['Pfam ID'].unique()))+' of the affected domains have known interactions.' ) \n",
    "\n",
    "\n",
    "                # Identify binding of affected domains = Edges in the PPI\n",
    "                self.interacting_domains=affected_edges(self.data,Join,self.mapping)\n",
    "\n",
    "\n",
    "\n",
    "                #get all edges of a gene\n",
    "                self.g2edges=gene_to_edges(self.interacting_domains)\n",
    "                \n",
    "                print(str(len([item for sublist in self.g2edges.values() for item in sublist]))+' protein interactions/binding affected.')\n",
    "\n",
    "                \n",
    "                # Runing Enrichment analysis\n",
    "                \n",
    "                print('\\n**************************************************')\n",
    "                print('Running enrichment analysis...')\n",
    "                \n",
    "                self.supported_database=  list(self.path['source'].unique())\n",
    "                self.enrichment=pathway_enrichment(self.g2edges,self.path, self.mapping,organism).reset_index(drop=True)\n",
    "                print('NEASE enrichment done.')\n",
    "                \n",
    "    def get_domains(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Display the list of AS events in NEASE format.\n",
    "         \"\"\"\n",
    "                \n",
    "        if len(self.data)==0 :\n",
    "            print('Processing failed')\n",
    "\n",
    "            \n",
    "        elif self.organism==\"Mouse\":\n",
    "                #no visualization available for mouse in DIGGER\n",
    "                return self.data.drop(columns=['Domain ID','Visualization link'])\n",
    "        else:\n",
    "            \n",
    "            #DIGGER visualization available for Human\n",
    "            return self.data.drop(columns=[ 'Domain ID'])\n",
    "    \n",
    "    \n",
    "    def get_edges(self):\n",
    "        \n",
    "        \"\"\"   \n",
    "            Display affected interactions from AS. \n",
    "        \"\"\"\n",
    "        if len(self.data)==0:\n",
    "            print('Processing failed')\n",
    "        elif len(self.interacting_domains)==0:\n",
    "            print('No affected edges identified.')\n",
    "        else:\n",
    "            edges=self.interacting_domains[['Gene name','NCBI gene ID','dPSI','Pfam ID','Number of affected interactions','Affected binding','Affected binding (NCBI)']]\n",
    "            a=lambda x: \",\".join(x)\n",
    "            edges['Affected binding']=edges['Affected binding'].apply(a)\n",
    "            edges['Affected binding (NCBI)']=edges['Affected binding (NCBI)'].apply(a)\n",
    "            edges=edges.drop_duplicates()\n",
    "            edges=edges.sort_values('Number of affected interactions', ascending=False)\n",
    "\n",
    "            return edges.reset_index(drop=True)\n",
    "    \n",
    "          \n",
    "    \n",
    "    def enrich(self, database=  ['PharmGKB',\n",
    "                                 'HumanCyc',\n",
    "                                 'Wikipathways',\n",
    "                                 'Reactome',\n",
    "                                 'KEGG',\n",
    "                                 'SMPDB',\n",
    "                                 'Signalink',\n",
    "                                 'NetPath',\n",
    "                                 'EHMN',\n",
    "                                 'INOH',\n",
    "                                 'BioCarta',\n",
    "                                 'PID'], cutoff=0.05 ):\n",
    "        \n",
    "        \"\"\" \n",
    "        Run enrichement analysis\n",
    "        database: List of gene set sources for enrichment.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.data)==0:\n",
    "            print('Processing failed')\n",
    "        elif len(self.interacting_domains)==0:\n",
    "            print('No affected edges identified.') \n",
    "        \n",
    "        else:\n",
    "            # Check if user input matches the available databases\n",
    "            database=[ x for x in database if x in self.supported_database]\n",
    "\n",
    "            if len(database)==0: \n",
    "                print('Please select a supported pathway database as an argument. ')\n",
    "                print('supported databases for '+self.organism+' are :',[ x for x in  self.supported_database],\".\")\n",
    "                print('\\n')\n",
    "            else:\n",
    "\n",
    "\n",
    "                enrich_results=self.enrichment[self.enrichment['Source'].isin(database)]\n",
    "                \n",
    "                # Correct for multiple testing\n",
    "                # fdr_bh : Benjamini/Hochberg (non-negative)\n",
    "                #enrich_results['adj p_value']=sm.stats.multipletests(list(enrich_results['p_value']),method='fdr_bh',alpha=0.1)[1]\n",
    "                enrich_results['adj p_value']=sm.stats.fdrcorrection(list(enrich_results['p_value']))[1]\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                print('NEASE enrichment for the pathway databases:\\n',[ x for x in database])\n",
    "                num=len(enrich_results[enrich_results['adj p_value']<=cutoff])\n",
    "                if num==0:\n",
    "                    print('No enrichment found with the cutoff '+str(cutoff)+'.')\n",
    "                else:\n",
    "                    print(\"Found \"+str(num)+\" enriched pathways after multiple test correction.\\n\")\n",
    "\n",
    "                return enrich_results.sort_values(['p_value']).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    def path_analysis(self,path_id):\n",
    "        \n",
    "        '''\n",
    "        Run enrichment analysis on a specific pathway with details of impact of AS.\n",
    "        '''\n",
    "            \n",
    "        if len(self.data)==0:\n",
    "            print('Processing failed')\n",
    "        elif len(self.interacting_domains)==0:\n",
    "            print('No affected edges identified.') \n",
    "            \n",
    "            \n",
    "        path_info=self.enrichment[self.enrichment['Pathway ID']==path_id]\n",
    "        \n",
    "        if len(path_info)==0:\n",
    "            print('No pathway with the given ID found.')\n",
    "        \n",
    "        else:\n",
    "            path_name=list(path_info['Pathway name'])[0]\n",
    "            print('Enrichment of the pathway: '+path_name+'.\\n')\n",
    "            print('Overall p_value: ',list(path_info['p_value'])[0])\n",
    "            print('\\n')\n",
    "            # run enrichment\n",
    "            enrich=single_path_enrich(path_id,self.path,self.g2edges,self.mapping,self.organism)\n",
    "            \n",
    "            if len(enrich)==0:\n",
    "                print('No enrichment or genes found for the selected pathway.')\n",
    "            else:\n",
    "                return enrich.sort_values(['p_value']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rMATS dexeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tData Summary\n",
      "**************************************************\n",
      "191 protein domains are affected by AS.\n",
      "95 of the affected domains have known interactions.\n",
      "985 protein interactions/binding affected.\n",
      "\n",
      "**************************************************\n",
      "Running enrichment analysis...\n"
     ]
    }
   ],
   "source": [
    "events=NEASE(table_dcm, organism='Human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#events=NEASE(table, organism='Human',input_type='MAJIQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.get_domains().head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.enrich(database=['KEGG']).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.path_analysis('path:hsa05414')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.path_analysis('R-HSA-445095')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.path_analysis('path:hsa04261')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.path_analysis('path:hsa04022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.path_analysis(path_id='R-HSA-76002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
